{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0378d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Dependencies\"\n",
    "\n",
    "%%capture\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.special import gammainc, gamma\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install \"cdsapi>=0.7.4\"\n",
    "import cdsapi\n",
    "\n",
    "!pip install cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf90240",
   "metadata": {
    "need_format": true
   },
   "outputs": [],
   "source": [
    "# Section \"Parameters\"\n",
    "\n",
    "spi_ts = 1\n",
    "\n",
    "area = [6.6283, 36.6196, 18.7669, 47.0921] # min_lon, min_lat, max_lon, max_lat\n",
    "\n",
    "reference_period = (1981, 2010) # start_year, end_year\n",
    "\n",
    "period_of_interest = ('2024-01', '2025-01') # start_month, end_month\n",
    "\n",
    "cds_client = cdsapi.Client(url='https://cds.climate.copernicus.eu/api', key=getpass.getpass(\"YOUR CDS-API-KEY\")) # CDS client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ba805",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'era5_land__total_precipitation__{{\"_\".join([str(c) for c in area])}}__monthly__{{reference_period[0]}}_{{reference_period[1]:02d}}.nc'\n",
    "\n",
    "out_dir = 'tmpdir'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "cds_out_filename = os.path.join(out_dir, filename)\n",
    "\n",
    "if not os.path.exists(cds_out_filename):\n",
    "    cds_dataset = 'reanalysis-era5-land-monthly-means'\n",
    "    cds_query =  {{\n",
    "        'product_type': 'monthly_averaged_reanalysis',\n",
    "        'variable': 'total_precipitation',\n",
    "        'year': [str(year) for year in range(*reference_period)],\n",
    "        'month': [f'{{month:02d}}' for month in range(1, 13)],\n",
    "        'time': '00:00',\n",
    "        'area': [\n",
    "            area[3],  # N\n",
    "            area[0],  # W\n",
    "            area[1],  # S\n",
    "            area[2]   # E\n",
    "        ],\n",
    "        \"data_format\": \"netcdf\",\n",
    "        \"download_format\": \"unarchived\"\n",
    "    }}\n",
    "\n",
    "    cds_client.retrieve(cds_dataset, cds_query, cds_out_filename)\n",
    "\n",
    "cds_ref_data = xr.open_dataset(cds_out_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039befb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get (Years, Years-Months) couple for the CDS api query. (We can query just one month at time)\n",
    "period_of_interest = (datetime.datetime.strptime(period_of_interest[0], \"%Y-%m\"), datetime.datetime.strptime(period_of_interest[1], \"%Y-%m\"))\n",
    "spi_start_date = period_of_interest[0] - relativedelta(months=spi_ts-1)\n",
    "spi_years_range = list(range(spi_start_date.year, period_of_interest[1].year+1))\n",
    "spi_month_range = []\n",
    "for iy,year in enumerate(range(spi_years_range[0], spi_years_range[-1]+1)):\n",
    "    if iy==0 and len(spi_years_range)==1:\n",
    "        spi_month_range.append([month for month in range(spi_start_date.month, period_of_interest[1].month+1)])\n",
    "    elif iy==0 and len(spi_years_range)>1:\n",
    "        spi_month_range.append([month for month in range(spi_start_date.month, 13)])\n",
    "    elif iy>0 and iy==len(spi_years_range)-1:\n",
    "        spi_month_range.append([month for month in range(1, period_of_interest[1].month+1)])\n",
    "    else:\n",
    "        spi_month_range.append([month for month in range(1, 13)])\n",
    "\n",
    "def build_cds_hourly_data_filepath(year, month):\n",
    "    dataset_part = 'reanalysis_era5_land__total_precipitation__hourly'\n",
    "    time_part = f'{{year}}-{{month[0]:02d}}_{{year}}-{{month[-1]:02d}}'\n",
    "    filename = f'{{dataset_part}}__{{\"_\".join([str(c) for c in area])}}__{{time_part}}.nc'\n",
    "    filedir = os.path.join(out_dir, dataset_part)\n",
    "    if not os.path.exists(filedir):\n",
    "        os.makedirs(filedir, exist_ok=True)\n",
    "    filepath = os.path.join(filedir, filename)\n",
    "    return filepath\n",
    "\n",
    "def floor_decimals(number, decimals=0):\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(number * factor) / factor\n",
    "\n",
    "def ceil_decimals(number, decimals=0):\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "# CDS API query\n",
    "cds_poi_data_filepaths = []\n",
    "for q_idx, (year,year_months) in enumerate(zip(spi_years_range, spi_month_range)):\n",
    "    for ym in year_months:\n",
    "        cds_poi_data_filepath = build_cds_hourly_data_filepath(year, [ym])\n",
    "        if not os.path.exists(cds_poi_data_filepath):\n",
    "            cds_dataset = 'reanalysis-era5-land'\n",
    "            cds_query =  {{\n",
    "                'variable': 'total_precipitation',\n",
    "                'year': [str(year)],\n",
    "                'month': [f'{{month:02d}}' for month in year_months],\n",
    "                'day': [f'{{day:02d}}' for day in range(1, 32)],\n",
    "                'time': [f'{{hour:02d}}:00' for hour in range(0, 24)],\n",
    "                'area': [\n",
    "                    ceil_decimals(area[3], 1),    # N\n",
    "                    floor_decimals(area[0], 1),   # W\n",
    "                    floor_decimals(area[1], 1),   # S\n",
    "                    ceil_decimals(area[2], 1),    # E\n",
    "                ],\n",
    "                \"data_format\": \"netcdf\",\n",
    "                \"download_format\": \"unarchived\"\n",
    "            }}\n",
    "            cds_client.retrieve(cds_dataset, cds_query, cds_poi_data_filepath)\n",
    "\n",
    "    print(f'{{q_idx+1}}/{{len(year_months)}}/{{len(spi_years_range)}} - CDS API query completed')\n",
    "    cds_poi_data_filepaths.append(cds_poi_data_filepath)\n",
    "\n",
    "cds_poi_data = [xr.open_dataset(fp) for fp in cds_poi_data_filepaths]\n",
    "cds_poi_data = xr.concat(cds_poi_data, dim='valid_time')\n",
    "cds_poi_data = cds_poi_data.sel(valid_time=(cds_poi_data.valid_time.dt.date>=period_of_interest[0].date()) & (cds_poi_data.valid_time.dt.date<=period_of_interest[1].date()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess reference dataset\n",
    "cds_ref_data = cds_ref_data.drop_vars(['number', 'expver'])\n",
    "cds_ref_data = cds_ref_data.rename({{'valid_time': 'time', 'latitude': 'lat', 'longitude': 'lon'}})\n",
    "cds_ref_data = cds_ref_data * cds_ref_data['time'].dt.days_in_month\n",
    "cds_ref_data = cds_ref_data.assign_coords(\n",
    "    lat=np.round(cds_ref_data.lat.values, 6),\n",
    "    lon=np.round(cds_ref_data.lon.values, 6),\n",
    ")\n",
    "cds_ref_data = cds_ref_data.sortby(['time', 'lat', 'lon'])\n",
    "\n",
    "# Preprocess period-of-interest dataset\n",
    "cds_poi_data = cds_poi_data.drop_vars(['number', 'expver'])\n",
    "cds_poi_data = cds_poi_data.rename({{'valid_time': 'time', 'latitude': 'lat', 'longitude': 'lon'}})\n",
    "cds_poi_data = cds_poi_data.resample(time='1ME').sum()                                   # Resample to monthly total data\n",
    "cds_poi_data = cds_poi_data.assign_coords(time=cds_poi_data.time.dt.strftime('%Y-%m-01'))  # Set month day to 01\n",
    "cds_poi_data = cds_poi_data.assign_coords(time=pd.to_datetime(cds_poi_data.time))\n",
    "cds_poi_data['tp'] = cds_poi_data['tp'] / 12                                              # Convert total precipitation to monthly average precipitation\n",
    "cds_poi_data = cds_poi_data.assign_coords(\n",
    "    lat=np.round(cds_poi_data.lat.values, 6),\n",
    "    lon=np.round(cds_poi_data.lon.values, 6),\n",
    ")\n",
    "cds_poi_data = cds_poi_data.sortby(['time', 'lat', 'lon'])\n",
    "\n",
    "# Get whole dataset\n",
    "ts_dataset = xr.concat([cds_ref_data, cds_poi_data], dim='time')\n",
    "ts_dataset = ts_dataset.drop_duplicates(dim='time').sortby(['time', 'lat', 'lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SPI function\n",
    "def compute_timeseries_spi(monthly_data, spi_ts, nt_return=1):\n",
    "    # Compute SPI index for a time series of monthly data\n",
    "    # REF: https://drought.emergency.copernicus.eu/data/factsheets/factsheet_spi.pdf\n",
    "    # REF: https://mountainscholar.org/items/842b69e8-a465-4aeb-b7ec-021703baa6af [ page 18 to 24 ]\n",
    "    \n",
    "    # SPI calculation needs finite-values and non-zero values\n",
    "    if all([md<=0 for md in monthly_data]):\n",
    "        return 0\n",
    "    if all([np.isnan(md) or md==0 for md in monthly_data]):\n",
    "        return np.nan\n",
    "    \n",
    "    df = pd.DataFrame({{'monthly_data': monthly_data}})\n",
    "\n",
    "    # Totalled data over t_scale rolling windows\n",
    "    if spi_ts > 1:\n",
    "        t_scaled_monthly_data = df.rolling(spi_ts).sum().monthly_data.iloc[spi_ts:]\n",
    "    else:\n",
    "        t_scaled_monthly_data = df.monthly_data\n",
    "\n",
    "    # Gamma fitted params\n",
    "    a, _, b = stats.gamma.fit(t_scaled_monthly_data, floc=0)\n",
    "\n",
    "    # Cumulative probability distribution\n",
    "    G = lambda x: stats.gamma.cdf(x, a=a, loc=0, scale=b)\n",
    "\n",
    "    m = (t_scaled_monthly_data==0).sum()\n",
    "    n = len(t_scaled_monthly_data)\n",
    "    q = m / n # zero prob\n",
    "\n",
    "    H = lambda x: q + (1-q) * G(x) # zero correction\n",
    "\n",
    "    t = lambda Hx: math.sqrt(\n",
    "        math.log(1 /\n",
    "        (math.pow(Hx, 2) if 0<Hx<=0.5 else math.pow(1-Hx, 2))\n",
    "    ))\n",
    "\n",
    "    c0, c1, c2 = 2.515517, 0.802853, 0.010328\n",
    "    d1, d2, d3 = 1.432788, 0.189269, 0.001308\n",
    "\n",
    "    Hxs = t_scaled_monthly_data[-spi_ts:].apply(H)\n",
    "    txs = Hxs.apply(t)\n",
    "\n",
    "    Z = lambda Hx, tx: ( tx - ((c0 + c1*tx + c2*math.pow(tx,2)) / (1 + d1*tx + d2*math.pow(tx,2) + d3*math.pow(tx,3) )) ) * (-1 if 0<Hx<=0.5 else 1)\n",
    "\n",
    "    spi_t_indexes = pd.DataFrame(zip(Hxs, txs), columns=['H','t']).apply(lambda x: Z(x.H, x.t), axis=1).to_list()\n",
    "\n",
    "    return np.array(spi_t_indexes[-nt_return]) if nt_return==1 else np.array(spi_t_indexes[-nt_return:])\n",
    "\n",
    "# Compute SPI over each cell\n",
    "month_spi_coverages = []\n",
    "for month in cds_poi_data.time:\n",
    "    month_spi_coverage = xr.apply_ufunc(\n",
    "        lambda tile_timeseries: compute_timeseries_spi(tile_timeseries, spi_ts=spi_ts, nt_return=1),\n",
    "        ts_dataset.sel(time=ts_dataset.time<=month).tp.sortby('time'),\n",
    "        input_core_dims = [['time']],\n",
    "        vectorize = True\n",
    "    )\n",
    "    month_spi_coverages.append((\n",
    "        month.dt.date.item(),\n",
    "        month_spi_coverage\n",
    "    ))\n",
    "\n",
    "# Create SPI dataset\n",
    "spi_times = [msc[0] for msc in month_spi_coverages]\n",
    "spi_grids = [msc[1] for msc in month_spi_coverages]\n",
    "\n",
    "spi_dataset = xr.concat(spi_grids, dim='time').to_dataset()\n",
    "spi_dataset = spi_dataset.assign_coords({{'time': spi_times}})\n",
    "spi_dataset = spi_dataset.rename_vars({{'tp': 'spi'}})\n",
    "\n",
    "spi_values = spi_dataset.spi.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable \"spi_dataset\" is a xarray.Dataset with three dimensions ('time', 'lat', 'lon') and a 'spi' var related to those dimensions\n",
    "display(spi_dataset)\n",
    "\n",
    "# variable \"spi_values\" is a numpy.array with shape (time, lat, lon) and it is representig numerical values of spi index over each time for each lat-lon cell\n",
    "display(spi_values) \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
